{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee216415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "ROOT_DIR = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = ROOT_DIR + \"/kitti/training/image_2\"\n",
    "label_path = ROOT_DIR + \"/kitti/training/gt_image_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_paths(label_path):\n",
    "    label_paths = {re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
    "                   for path in glob(os.path.join(label_path, '*_road_*.png'))}\n",
    "\n",
    "    return label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11728495",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_paths = get_label_paths(label_path)\n",
    "image_path = list(label_paths)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e480df",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(train_path, image_path), cv2.IMREAD_COLOR) # BGR 3 channel ndarray wiht shape H * W * 3\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert cv2 read image from BGR order to RGB order\n",
    "image = cv2.resize(image, (256, 256))\n",
    "image = np.float32(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ed860",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = imageio.imread(label_paths[image_path])\n",
    "label = cv2.resize(label, (256, 256))\n",
    "label = label[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_table = label == 255\n",
    "# label = label * truth_table\n",
    "# label = np.invert(label)\n",
    "label = truth_table.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90498f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/yoonwoo/cv/project-5-staff/Camvid/701_StillsRaw_full/0001TP_006690.png\"\n",
    "# path_label = \"/home/yoonwoo/cv/project-5-staff/Camvid/semseg11/0001TP_006690_L.png\"\n",
    "# image = cv2.imread(path)\n",
    "# camvid_label = imageio.imread(path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.distributed as dist\n",
    "\n",
    "from src.vision.utils import get_logger, save_json_dict, load_class_names\n",
    "from src.vision.iou import intersectionAndUnionGPU\n",
    "from src.vision.avg_meter import AverageMeter, SegmentationAverageMeter\n",
    "\n",
    "from src.vision.part2_dataset import SemData, KittiData\n",
    "from src.vision.part3_training_utils import (\n",
    "    get_model_and_optimizer,\n",
    "    get_train_transform,\n",
    "    get_val_transform,\n",
    "    update_learning_rate,\n",
    ")\n",
    "from src.vision.part5_pspnet import PSPNet\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    **{\n",
    "        # DATA\n",
    "        \"names_path\": \"./dataset_lists/camvid-11/camvid-11_names.txt\",\n",
    "        \"data_root\": \"./Camvid/\",\n",
    "        \"train_list\": \"./src/dataset_lists/camvid-11/list/train.txt\",  \n",
    "        \"val_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"classes\": 11,\n",
    "        # TRAIN\n",
    "        \"arch\": \"PSPNet\", #  \"SimpleSegmentationNet\", # \n",
    "        \"save_path\": \"\",\n",
    "        \"epochs\": 2,\n",
    "        \"zoom_factor\": 8,\n",
    "        \"use_ppm\": True,\n",
    "        \"aux_weight\": 0.4,\n",
    "        \"aux_loss\": True,\n",
    "        \"layers\": 50,\n",
    "        \"workers\": 2,\n",
    "        \"batch_size\": 32,\n",
    "        \"batch_size_val\": 32,\n",
    "        \"data_aug\": True,\n",
    "        \"short_size\": 240,\n",
    "        \"train_h\": 201,\n",
    "        \"train_w\": 201,\n",
    "        \"init_weight\": \"./initmodel/resnet50_v2.pth\",\n",
    "        \"scale_min\": 0.5,  # minimum random scale\n",
    "        \"scale_max\": 2.0,  # maximum random scale\n",
    "        \"rotate_min\": -10,  # minimum random rotate\n",
    "        \"rotate_max\": 10,  # maximum random rotate\n",
    "        \"ignore_label\": 255,\n",
    "        \"base_lr\": 0.01,\n",
    "        \"start_epoch\": 0,\n",
    "        \"power\": 0.9,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"manual_seed\": 0,\n",
    "        \"print_freq\": 10,\n",
    "        \"save_freq\": 1,\n",
    "        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n",
    "        \"multiprocessing_distributed\": False,\n",
    "        # INFERENCE\n",
    "        \"dataset\": \"camvid-11\",\n",
    "        \"base_size\": 240,\n",
    "        \"test_h\": 201,\n",
    "        \"test_w\": 201,\n",
    "        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        \"test_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"vis_freq\": 10,\n",
    "        \"pretrained\": True\n",
    "    }\n",
    ")\n",
    "args.save_path = f\"exp/camvid/{args.arch}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50702352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "\n",
    "def check(args):\n",
    "    assert args.classes > 1\n",
    "    assert args.zoom_factor in [1, 2, 4, 8]\n",
    "    if args.arch == \"psp\":\n",
    "        assert (args.train_h - 1) % 8 == 0 and (args.train_w - 1) % 8 == 0\n",
    "    else:\n",
    "        raise Exception(\"architecture not supported yet\".format(args.arch))\n",
    "\n",
    "def poly_learning_rate(base_lr: float, curr_iter, max_iter, power: float = 0.9) -> float:\n",
    "    \"\"\"Compute the learning rate at a specific iteration, given a polynomial learning rate policy.\"\"\"\n",
    "    lr = base_lr * (1 - float(curr_iter) / max_iter) ** power\n",
    "    return lr\n",
    "\n",
    "def main_worker(args, use_cuda: bool):\n",
    "    \"\"\" \"\"\"\n",
    "    model, optimizer = get_model_and_optimizer(args)\n",
    "    logger.info(args)\n",
    "    logger.info(\"=> creating model ...\")\n",
    "    logger.info(\"Classes: {}\".format(args.classes))\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # data_aug hyperparameter\n",
    "    if args.data_aug:\n",
    "        train_transform = get_train_transform(args)\n",
    "    else:\n",
    "        train_transform = get_val_transform(args)\n",
    "    train_data = SemData(\n",
    "        split=\"train\", data_root=args.data_root, data_list_fpath=args.train_list, transform=train_transform\n",
    "    )\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_transform = get_val_transform(args)\n",
    "    val_data = SemData(split=\"val\", data_root=args.data_root, data_list_fpath=args.val_list, transform=val_transform)\n",
    "\n",
    "    val_sampler = None\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_data,\n",
    "        batch_size=args.batch_size_val,\n",
    "        shuffle=False,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "        sampler=val_sampler,\n",
    "    )\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        epoch_log = epoch + 1\n",
    "        loss_train, mIoU_train, mAcc_train, allAcc_train = run_epoch(\n",
    "            args,\n",
    "            use_cuda,\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            split=\"train\",\n",
    "        )\n",
    "        results_dict[\"loss_train\"] += [round(float(loss_train), 3)]\n",
    "        results_dict[\"mIoU_train\"] += [round(float(mIoU_train), 3)]\n",
    "        results_dict[\"mAcc_train\"] += [round(float(mAcc_train), 3)]\n",
    "        results_dict[\"allAcc_train\"] += [round(float(allAcc_train), 3)]\n",
    "\n",
    "        if epoch_log % args.save_freq == 0:\n",
    "            filename = args.save_path + \"/train_epoch_\" + str(epoch_log) + \".pth\"\n",
    "            logger.info(\"Saving checkpoint to: \" + filename)\n",
    "            torch.save(\n",
    "                {\"epoch\": epoch_log, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}, filename\n",
    "            )\n",
    "            if epoch_log / args.save_freq > 2:\n",
    "                deletename = args.save_path + \"/train_epoch_\" + str(epoch_log - args.save_freq * 2) + \".pth\"\n",
    "                os.remove(deletename)\n",
    "        if args.evaluate:\n",
    "            with torch.no_grad():\n",
    "                loss_val, mIoU_val, mAcc_val, allAcc_val = run_epoch(\n",
    "                    args, use_cuda, val_loader, model, optimizer=None, epoch=epoch, split=\"val\"\n",
    "                )\n",
    "            results_dict[\"loss_val\"] += [round(float(loss_val), 3)]\n",
    "            results_dict[\"mIoU_val\"] += [round(float(mIoU_val), 3)]\n",
    "            results_dict[\"mAcc_val\"] += [round(float(mAcc_val), 3)]\n",
    "            results_dict[\"allAcc_val\"] += [round(float(allAcc_val), 3)]\n",
    "\n",
    "    logger.info(\"======> Training complete ======>\")\n",
    "    logger.info(\">>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>\")\n",
    "    with torch.no_grad():\n",
    "        loss_val, mIoU_val, mAcc_val, allAcc_val = run_epoch(\n",
    "            args, use_cuda, val_loader, model, optimizer=None, epoch=epoch, split=\"val\"\n",
    "        )\n",
    "    logger.info(\"<<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<\")\n",
    "    print(\"Results Dict: \", results_dict)\n",
    "    save_json_dict(os.path.join(args.save_path, \"training_results_dict.json\"), results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    args,\n",
    "    use_cuda: bool,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    split: str,\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Run the network over all examples within a dataset split. If this split is the train split, also run backprop.\n",
    "    \"\"\"\n",
    "    class_names = load_class_names(dataset_name=args.dataset)\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    main_loss_meter = AverageMeter()\n",
    "    aux_loss_meter = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    sam = SegmentationAverageMeter()\n",
    "\n",
    "    if split == \"train\":\n",
    "        model.train()\n",
    "    elif split in [\"val\", \"test\"]:\n",
    "        model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    max_iter = args.epochs * len(data_loader)\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        if args.zoom_factor != 8:\n",
    "            h = int((target.size()[1] - 1) / 8 * args.zoom_factor + 1)\n",
    "            w = int((target.size()[2] - 1) / 8 * args.zoom_factor + 1)\n",
    "            target = (\n",
    "                F.interpolate(target.unsqueeze(1).float(), size=(h, w), mode=\"bilinear\", align_corners=True)\n",
    "                .squeeze(1)\n",
    "                .long()\n",
    "            )\n",
    "\n",
    "        if use_cuda:\n",
    "            # input = input.cuda(non_blocking=True)\n",
    "            input = input.cuda()\n",
    "            # target = target.cuda(non_blocking=True)\n",
    "            target = target.cuda()\n",
    "\n",
    "        _, preds, main_loss, aux_loss = model(input, target)\n",
    "\n",
    "        # adding aux_loss hyperparameter\n",
    "        if not args.aux_loss:\n",
    "            aux_loss = torch.Tensor([0])\n",
    "\n",
    "        main_loss, aux_loss = torch.mean(main_loss), torch.mean(aux_loss)\n",
    "        loss = main_loss + args.aux_weight * aux_loss\n",
    "\n",
    "        if split == \"train\":\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        n = input.size(0)\n",
    "\n",
    "        sam.update_metrics_gpu(preds, target, args.classes, args.ignore_label, args.multiprocessing_distributed)\n",
    "\n",
    "        main_loss_meter.update(main_loss.item(), n)\n",
    "        aux_loss_meter.update(aux_loss.item(), n)\n",
    "        loss_meter.update(loss.item(), n)\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if split == \"train\":\n",
    "            current_iter = epoch * len(data_loader) + i + 1\n",
    "            current_lr = poly_learning_rate(args.base_lr, current_iter, max_iter, power=args.power)\n",
    "\n",
    "            optimizer = update_learning_rate(current_lr, optimizer)\n",
    "\n",
    "            remain_iter = max_iter - current_iter\n",
    "            remain_time = remain_iter * batch_time.avg\n",
    "            t_m, t_s = divmod(remain_time, 60)\n",
    "            t_h, t_m = divmod(t_m, 60)\n",
    "            remain_time = \"{:02d}:{:02d}:{:02d}\".format(int(t_h), int(t_m), int(t_s))\n",
    "        else:\n",
    "            remain_time = 0  # dummy value\n",
    "\n",
    "        if (i + 1) % args.print_freq == 0:\n",
    "\n",
    "            iou_class, accuracy_class, mIoU, mAcc, allAcc = sam.get_metrics()\n",
    "\n",
    "            logger_message = f\"{split} Epoch: [{epoch + 1}/{args.epochs}][{i+1}/{len(data_loader)}] \"\n",
    "            logger_message += f\"mIoU {mIoU} \"\n",
    "            logger_message += f\"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n",
    "            logger_message += f\"Batch {batch_time.val:.3f} ({batch_time.avg:.3f}) \"\n",
    "            logger_message += f\"Remain {remain_time} \"\n",
    "            logger_message += f\"MainLoss {main_loss_meter.val:.4f} \"\n",
    "            logger_message += f\"AuxLoss {aux_loss_meter.val:.4f} \"\n",
    "            logger_message += f\"Loss {loss_meter.val:.4f} \"\n",
    "            logger.info(logger_message)\n",
    "\n",
    "    iou_class, accuracy_class, mIoU, mAcc, allAcc = sam.get_metrics()\n",
    "\n",
    "    if split == \"train\":\n",
    "        logger.info(\n",
    "            \"Train result at epoch [{}/{}]: mIoU/mAcc/allAcc {:.4f}/{:.4f}/{:.4f}.\".format(\n",
    "                epoch + 1, args.epochs, mIoU, mAcc, allAcc\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        logger.info(f\"Val result: mIoU/mAcc/allAcc {mIoU:.4f}/{mAcc:.4f}/{allAcc:.4f}.\")\n",
    "        for i in range(args.classes):\n",
    "            logger.info(\n",
    "                f\"Class_{i} - {class_names[i]} Result: iou/accuracy {iou_class[i]:.4f}/{accuracy_class[i]:.4f}.\"\n",
    "            )\n",
    "        logger.info(\"<<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<\")\n",
    "\n",
    "    return main_loss_meter.avg, mIoU, mAcc, allAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ab414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# import torch\n",
    "\n",
    "# os.makedirs(args.save_path, exist_ok=True)\n",
    "# # from src.vision.trainer import main_worker\n",
    "# print(args)\n",
    "# main_worker(args, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"------------------------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_root = \"./kitti\"\n",
    "args.classes = 2\n",
    "args.save_path = f\"exp/kitti/{args.arch}/model\"\n",
    "args.batch_size = 32\n",
    "args.batch_size_val = 1\n",
    "args.train_h = 201\n",
    "args.train_w = 201\n",
    "args.dataset = \"kitti\"\n",
    "args.evaluate = True\n",
    "args.epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bcaf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = KittiData(split=\"train\", data_root=args.data_root, transform=None)\n",
    "test_data = KittiData(split=\"test\", data_root=args.data_root, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db256c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(train_data.train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7948e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker_kitti(args, use_cuda: bool):\n",
    "    \"\"\" \"\"\"\n",
    "    model, optimizer = get_model_and_optimizer(args)\n",
    "    logger.info(args)\n",
    "    logger.info(\"=> creating model ...\")\n",
    "    logger.info(\"Classes: {}\".format(args.classes))\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # data_aug hyperparameter\n",
    "    if args.data_aug:\n",
    "        train_transform = get_train_transform(args)\n",
    "    else:\n",
    "        train_transform = get_val_transform(args)\n",
    "    train_data = KittiData(split=\"train\", data_root=args.data_root, transform=train_transform)\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_transform = get_val_transform(args)\n",
    "    val_data = KittiData(split=\"test\", data_root=args.data_root, transform=val_transform)\n",
    "\n",
    "    val_sampler = None\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_data,\n",
    "        batch_size=args.batch_size_val,\n",
    "        shuffle=False,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "        sampler=val_sampler,\n",
    "    )\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        epoch_log = epoch + 1\n",
    "        loss_train, mIoU_train, mAcc_train, allAcc_train = run_epoch(\n",
    "            args,\n",
    "            use_cuda,\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            split=\"train\",\n",
    "        )\n",
    "        results_dict[\"loss_train\"] += [round(float(loss_train), 3)]\n",
    "        results_dict[\"mIoU_train\"] += [round(float(mIoU_train), 3)]\n",
    "        results_dict[\"mAcc_train\"] += [round(float(mAcc_train), 3)]\n",
    "        results_dict[\"allAcc_train\"] += [round(float(allAcc_train), 3)]\n",
    "\n",
    "        if epoch_log % args.save_freq == 0:\n",
    "            filename = args.save_path + \"/train_epoch_\" + str(epoch_log) + \".pth\"\n",
    "            logger.info(\"Saving checkpoint to: \" + filename)\n",
    "            torch.save(\n",
    "                {\"epoch\": epoch_log, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}, filename\n",
    "            )\n",
    "            if epoch_log / args.save_freq > 2:\n",
    "                deletename = args.save_path + \"/train_epoch_\" + str(epoch_log - args.save_freq * 2) + \".pth\"\n",
    "                os.remove(deletename)\n",
    "        if args.evaluate:\n",
    "            with torch.no_grad():\n",
    "                loss_val, mIoU_val, mAcc_val, allAcc_val = run_epoch(\n",
    "                    args, use_cuda, val_loader, model, optimizer=None, epoch=epoch, split=\"val\"\n",
    "                )\n",
    "            results_dict[\"loss_val\"] += [round(float(loss_val), 3)]\n",
    "            results_dict[\"mIoU_val\"] += [round(float(mIoU_val), 3)]\n",
    "            results_dict[\"mAcc_val\"] += [round(float(mAcc_val), 3)]\n",
    "            results_dict[\"allAcc_val\"] += [round(float(allAcc_val), 3)]\n",
    "\n",
    "    logger.info(\"======> Training complete ======>\")\n",
    "    logger.info(\">>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>\")\n",
    "    with torch.no_grad():\n",
    "        loss_val, mIoU_val, mAcc_val, allAcc_val = run_epoch(\n",
    "            args, use_cuda, val_loader, model, optimizer=None, epoch=epoch, split=\"val\"\n",
    "        )\n",
    "    logger.info(\"<<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<\")\n",
    "    print(\"Results Dict: \", results_dict)\n",
    "    save_json_dict(os.path.join(args.save_path, \"training_results_dict.json\"), results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb64eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "main_worker_kitti(args, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d03d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pdb\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "import src.vision.cv2_transforms as transform\n",
    "from src.vision.avg_meter import AverageMeter\n",
    "from src.vision.part5_pspnet import PSPNet\n",
    "from src.vision.part4_segmentation_net import SimpleSegmentationNet\n",
    "from src.vision.utils import load_class_names, get_imagenet_mean_std, get_logger, normalize_img\n",
    "from src.vision.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "_ROOT = Path(__file__).resolve().parent.parent.parent\n",
    "\n",
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(args, use_cuda: bool):\n",
    "    \"\"\"Load Pytorch pre-trained PSPNet model from disk of type torch.nn.DataParallel.\n",
    "\n",
    "    Note that `args.num_model_classes` will be size of logits output.\n",
    "\n",
    "    Args:\n",
    "        args:\n",
    "        use_cuda:\n",
    "\n",
    "    Returns:\n",
    "        model\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=args.ignore_label)\n",
    "\n",
    "    model = PSPNet(\n",
    "        layers=args.layers,\n",
    "        num_classes=11,\n",
    "        zoom_factor=args.zoom_factor,\n",
    "        criterion=criterion,\n",
    "        pretrained=False\n",
    "    )\n",
    "\n",
    "    # logger.info(model)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if os.path.isfile(args.model_path):\n",
    "        logger.info(f\"=> loading checkpoint '{args.model_path}'\")\n",
    "        if use_cuda:\n",
    "            checkpoint = torch.load(args.model_path)\n",
    "        else:\n",
    "            checkpoint = torch.load(args.model_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "        logger.info(f\"=> loaded checkpoint '{args.model_path}'\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"=> no checkpoint found at '{args.model_path}'\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43032830",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_200.pth\"\n",
    "args.classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_model(args.model_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57908e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "proj6_colab2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
